{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hybrid.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsSS+baGOOl3gUggoneL7p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pj747/qml-experiments/blob/main/Hybrid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2MJ8fEoVqag"
      },
      "source": [
        "###Required packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOfZ7Oiwaief",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97d864c-1b11-4aaa-a3b4-c32e4ca3398b"
      },
      "source": [
        "!pip install pennylane --upgrade\n",
        "# !pip install pennylane-qulacs[\"gpu\"] --upgrade"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pennylane in /usr/local/lib/python3.7/dist-packages (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: semantic-version==2.6 in /usr/local/lib/python3.7/dist-packages (from pennylane) (2.6.0)\n",
            "Requirement already satisfied, skipping upgrade: appdirs in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied, skipping upgrade: autoray in /usr/local/lib/python3.7/dist-packages (from pennylane) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: toml in /usr/local/lib/python3.7/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: autograd in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.7/dist-packages (from pennylane) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->pennylane) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->pennylane) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEP3SSThY1Gl"
      },
      "source": [
        "import pennylane as qml\n",
        "from pennylane import qnn\n",
        "import torch\n",
        "from pennylane import numpy as np\n",
        "from types import SimpleNamespace\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import math"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJTVCV_H-Qq3"
      },
      "source": [
        "# !pip install wandb\n",
        "# !wandb login"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58P_MYEpOiuv"
      },
      "source": [
        "###Global config\n",
        "For the rest of the notebook, config needs to be defined here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C745jEVOL9s"
      },
      "source": [
        "config = SimpleNamespace(\n",
        "    standardScaling = \"Yes\",\n",
        "    numQubits = 2,\n",
        "    vectorNorm = \"Yes\",\n",
        "    numLayers = 1,\n",
        "    end = \"classical\",\n",
        "    fullEntangle = \"Yes\",\n",
        "    epochs = 6,\n",
        "    hiddenLayer = 5,\n",
        "    start = \"quantum\"\n",
        ")"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw2a96lGNIGD"
      },
      "source": [
        "###Data Preparation\n",
        "The Wisconsin Breast Cancer dataset is prepared for two prediction formats - a list of one-hot vectors for a classical neural network, and a list of label predictions for the quantum case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNYKVurzu7R8"
      },
      "source": [
        "dataSet = load_breast_cancer()\n",
        "X = dataSet.data\n",
        "Y = dataSet.target\n",
        "if config.standardScaling:\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "Y_label = Y * 2 - np.ones(len(Y))\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_label, test_size=0.1, random_state=1)\n",
        "\n",
        "Y_01_train = torch.as_tensor(((Y_train + np.ones(len(Y_train)))//2)).to(torch.int64)\n",
        "Y_hot_train = torch.nn.functional.one_hot(Y_01_train, num_classes=2)\n",
        "\n",
        "Y_01_test = torch.as_tensor(((Y_test + np.ones(len(Y_test)))//2)).to(torch.int64)\n",
        "Y_hot_test = torch.nn.functional.one_hot(Y_01_test, num_classes=2)"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKi6D-wVUa2m"
      },
      "source": [
        "### Quantum circuit creation\n",
        "This cell sets up a quantum circuit with the appropriate configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ9xITmQjg0X"
      },
      "source": [
        "numQubits = config.numQubits\n",
        "dev = qml.device(\"default.qubit\", wires=numQubits)\n",
        "@qml.qnode(dev)\n",
        "def qcircuit(inputs, weights):\n",
        "    for i in range(config.numLayers):\n",
        "        if config.vectorNorm == \"Yes\":\n",
        "            norm = np.linalg.norm(inputs.clone().detach())\n",
        "            norm = norm if norm !=0 else 1\n",
        "        else:\n",
        "            norm = 2 * math.pi\n",
        "        for k in range(0, len(inputs)-numQubits, numQubits):\n",
        "            for j in range(numQubits):\n",
        "                qml.RX(inputs[k+j]*2*math.pi/norm, wires=j)\n",
        "        for j in range(numQubits):\n",
        "            qml.Rot(weights[j][i][0], weights[j][i][1], weights[j][i][2], wires = [j])\n",
        "        if config.fullEntangle == \"Yes\":\n",
        "            for j in range(numQubits):\n",
        "                for i in range(j):\n",
        "                    qml.CZ(wires=[j,i])\n",
        "        else:\n",
        "            for j in range(numQubits-1):\n",
        "                qml.CZ(wires=[j,j+1])\n",
        "        \n",
        "        ##qml.Rot(*weights[0], wires=[0])\n",
        "    if config.end == \"quantum\":   \n",
        "        return qml.expval(qml.PauliZ(0))\n",
        "    else:\n",
        "        return [qml.expval(qml.PauliZ(wires=i)) for i in range(numQubits)]\n",
        "\n",
        "weight_shapes = {\"weights\" : (config.numQubits, config.numLayers, 3)}\n",
        "qnode = getQuantumCircuit(config)\n",
        "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "# numQubits = config.numQubits\n",
        "# dev = qml.device(\"default.qubit\", wires=numQubits)\n",
        "\n",
        "# @qml.qnode(dev)\n",
        "# def qnode(inputs, weights):\n",
        "#     if config.vectorNorm == \"Yes\":\n",
        "#         norm = np.linalg.norm(inputs.clone().detach())\n",
        "#         norm = norm if norm !=0 else 1\n",
        "#     else:\n",
        "#         norm = 2 * math.pi\n",
        "#     for i in range(0,len(inputs), 2):\n",
        "#         qml.RX(inputs[i]*2*math.pi/norm, wires=[0])\n",
        "#         if i+1 < len(inputs):\n",
        "#             qml.RX(inputs[i+1]*2*math.pi/norm, wires=[1])\n",
        "#     qml.Rot(*weights[0], wires=[1])\n",
        "#     qml.CZ(wires=[0,1])\n",
        "#     # qml.templates.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "#     qml.Rot(*weights[1], wires=[0])\n",
        "#     return qml.expval(qml.PauliZ(wires=[0]))"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsVdCoSTUnjU"
      },
      "source": [
        "### Model creation\n",
        "This cell instantiates the actual model to be run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY-xjIqLj6el"
      },
      "source": [
        "if config.hiddenLayer != 0:\n",
        "    clayer_1 = torch.nn.Linear(30, config.hiddenLayer)\n",
        "    \n",
        "    if config.end == \"quantum\":\n",
        "        layers = [clayer_1, qlayer]\n",
        "    else:\n",
        "        clayer_2 = torch.nn.Linear(config.numQubits, 2)\n",
        "        softmax = torch.nn.Softmax(dim=1)\n",
        "        if config.start == \"classical\":\n",
        "            layers = [clayer_1, qlayer, clayer_2, softmax]\n",
        "        else:\n",
        "            layers = [qlayer, clayer_2, softmax]\n",
        "else:\n",
        "    layers = [qlayer]\n",
        "\n",
        "torch.nn.init.uniform_(qlayer.weights, a=0.0, b=0.001)\n",
        "model = torch.nn.Sequential(*layers)"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZrVleURUsUs"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbsfDBwPkYzq",
        "outputId": "ece37c66-07b6-4f30-f2cd-245be22dd688"
      },
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss = torch.nn.MSELoss()\n",
        "x_train = torch.tensor(X_train, requires_grad=True).float()\n",
        "\n",
        "y_train = torch.tensor(Y_train, requires_grad=False).float() if config.end == \"quantum\" else Y_hot_train.float()\n",
        "\n",
        "\n",
        "batch_size = 5\n",
        "batches = y_train.shape[0]/batch_size // batch_size\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    list(zip(x_train, y_train)), batch_size=5, shuffle=True, drop_last=True\n",
        ")\n",
        "\n",
        "epochs = config.epochs\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    running_loss = 0\n",
        "\n",
        "    for xs, ys in data_loader:\n",
        "        opt.zero_grad()\n",
        "\n",
        "        loss_evaluated = loss(model(xs), ys)\n",
        "        loss_evaluated.backward()\n",
        "\n",
        "        opt.step()\n",
        "\n",
        "        running_loss += loss_evaluated\n",
        "\n",
        "    avg_loss = running_loss / batches\n",
        "    print(\"Average loss over epoch {}: {:.4f}\".format(epoch + 1, avg_loss))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average loss over epoch 1: 1.2183\n",
            "Average loss over epoch 2: 1.1840\n",
            "Average loss over epoch 3: 1.1815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8PDlZS2Uxfp"
      },
      "source": [
        "### Training set accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx-K53DzUFfe"
      },
      "source": [
        "y_pred = model(x_train)\n",
        "y_pred = y_pred.detach().numpy()  \n",
        "if config.end == \"quantum\":\n",
        "    threshold = lambda x: 1 if x > 0 else -1 \n",
        "    vfunc = np.vectorize(threshold)\n",
        "    y_pred = vfunc(y_pred)\n",
        "    actual = Y_train\n",
        "else:\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    actual = Y_01_train.detach().numpy()\n",
        "\n",
        "print(y_pred)\n",
        "correct = [1 if p == p_true else 0 for p, p_true in zip(y_pred, actual)]\n",
        "accuracy = sum(correct) / len(correct)\n",
        "print(f\"Accuracy: {accuracy * 100}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duqIyULqU0_t"
      },
      "source": [
        "### Testing set accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhOllky5A6SA"
      },
      "source": [
        "x_test = torch.tensor(X_test, requires_grad=True).float()\n",
        "y_pred = model(x_test)\n",
        "y_pred = y_pred.detach().numpy()  \n",
        "if config.end == \"quantum\":\n",
        "    threshold = lambda x: 1 if x > 0 else -1 \n",
        "    vfunc = np.vectorize(threshold)\n",
        "    y_pred = vfunc(y_pred)\n",
        "    actual = Y_test\n",
        "else:\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    actual = Y_01_test.detach().numpy()\n",
        "\n",
        "print(y_pred)\n",
        "correct = [1 if p == p_true else 0 for p, p_true in zip(y_pred, actual)]\n",
        "accuracy = sum(correct) / len(correct)\n",
        "print(f\"Accuracy: {accuracy * 100}%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}