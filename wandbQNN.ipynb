{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wandbQNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP8piV66LYCyUTSYYhviYkm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "baaa4e57f20643b58865ac3350c38d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6079b116fcd54bc79c6d07ee83a31e95",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_83512aa97c7f4fc0b3a00cac37f1e9b0",
              "IPY_MODEL_5951537fcd36424985cd7af35e9c97ad"
            ]
          }
        },
        "6079b116fcd54bc79c6d07ee83a31e95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83512aa97c7f4fc0b3a00cac37f1e9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_b30291c4a01743c7b3c2256e0ee9a64c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a28acdd402824d3d83776461659ac3be"
          }
        },
        "5951537fcd36424985cd7af35e9c97ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eb058114cb784a278d6f26830c13381c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b89fd0cf70d944fe86ac68f2f0e8ad17"
          }
        },
        "b30291c4a01743c7b3c2256e0ee9a64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a28acdd402824d3d83776461659ac3be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb058114cb784a278d6f26830c13381c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b89fd0cf70d944fe86ac68f2f0e8ad17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pj747/qml-experiments/blob/main/wandbQNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlP5fvVYaaBA",
        "outputId": "91ecd87a-79bd-47ae-88b8-4a140ab24020"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Hybrid.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1dfGZCYlB7p41Y9SOZS-oKcoCapN74N0h\n",
        "\n",
        "###Required packages\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# !pip install pennylane-qulacs[\"gpu\"] --upgrade\n",
        "!pip install pennylane --upgrade\n",
        "import pennylane as qml\n",
        "from pennylane import qnn\n",
        "import torch\n",
        "from pennylane import numpy as np\n",
        "from types import SimpleNamespace\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import math"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pennylane\n",
            "  Using cached https://files.pythonhosted.org/packages/61/ad/d18c5113d7c536c7b4544c2741795af7abde9557ef433c7814aa7d10d845/PennyLane-0.16.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: networkx in /usr/local/lib/python3.7/dist-packages (from pennylane) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: appdirs in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.4)\n",
            "Collecting autoray\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/9f/6742425eba1664edc8d6e93dd4536f4552acacd1a7b3a7ac2871657c969a/autoray-0.2.5-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: autograd in /usr/local/lib/python3.7/dist-packages (from pennylane) (1.3)\n",
            "Collecting semantic-version==2.6\n",
            "  Downloading https://files.pythonhosted.org/packages/28/be/3a7241d731ba89063780279a5433f5971c1cf41735b64a9f874b7c3ff995/semantic_version-2.6.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: toml in /usr/local/lib/python3.7/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->pennylane) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->pennylane) (0.16.0)\n",
            "Installing collected packages: autoray, semantic-version, pennylane\n",
            "Successfully installed autoray-0.2.5 pennylane-0.16.0 semantic-version-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u9VNLeS2afDK",
        "outputId": "84234cdb-f7ba-493a-9621-6db518e18558"
      },
      "source": [
        "!pip install wandb\n",
        "!wandb login\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/f6/91c07f54c2162854f5028aaa13f576ca17a3bc0cf6da02c2ad5baddae128/wandb-0.10.33-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/41/75fad31fff378871c462745ce724b3701a6acad17028d79476ec2545e40f/sentry_sdk-1.3.0-py2.py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 24.2MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 21.4MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6502 sha256=3a530ccd9ee5b763427659d699817e6ecaa3ce7342aee894d0a8a04b43c8c0b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8807 sha256=aafc1e6d3f895fab546336fd393d6da3149439129c866e09acc08586904a9b95\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: docker-pycreds, subprocess32, pathtools, configparser, sentry-sdk, smmap, gitdb, GitPython, shortuuid, wandb\n",
            "Successfully installed GitPython-3.1.18 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 sentry-sdk-1.3.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "configparser"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E47g83jNaO_i"
      },
      "source": [
        "def wandbSweep(config):\n",
        "\n",
        "    \"\"\"###Data Preparation\n",
        "    The Wisconsin Breast Cancer dataset is prepared for two prediction formats - \n",
        "    a list of one-hot vectors for a classical neural network, and a list of label predictions for the quantum case.\n",
        "    \"\"\"\n",
        "\n",
        "    dataSet = load_breast_cancer()\n",
        "    X = dataSet.data\n",
        "    Y = dataSet.target\n",
        "    if config.standardScaling:\n",
        "        scaler = StandardScaler()\n",
        "        X = scaler.fit_transform(X)\n",
        "    Y_label = Y * 2 - np.ones(len(Y))\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y_label, test_size=0.1, random_state=1)\n",
        "\n",
        "    Y_01_train = torch.as_tensor(((Y_train + np.ones(len(Y_train)))//2)).to(torch.int64)\n",
        "    Y_hot_train = torch.nn.functional.one_hot(Y_01_train, num_classes=2)\n",
        "\n",
        "    Y_01_test = torch.as_tensor(((Y_test + np.ones(len(Y_test)))//2)).to(torch.int64)\n",
        "    Y_hot_test = torch.nn.functional.one_hot(Y_01_test, num_classes=2)\n",
        "\n",
        "    \"\"\"### Quantum circuit creation\n",
        "    This cell sets up a quantum circuit with the appropriate configuration\n",
        "    \"\"\"\n",
        "\n",
        "    numQubits = config.numQubits\n",
        "    dev = qml.device(\"default.qubit\", wires=numQubits)\n",
        "    @qml.qnode(dev)\n",
        "    def qnode(inputs, weights):\n",
        "        for i in range(config.numLayers):\n",
        "            if config.vectorNorm == \"Yes\":\n",
        "                norm = np.linalg.norm(inputs.clone().detach())\n",
        "                norm = norm if norm !=0 else 1\n",
        "            else:\n",
        "                norm = 2 * math.pi\n",
        "            for k in range(0, len(inputs)-numQubits, numQubits):\n",
        "                for j in range(numQubits):\n",
        "                    qml.RX(inputs[k+j]*2*math.pi/norm, wires=j)\n",
        "            for j in range(numQubits):\n",
        "                qml.Rot(weights[j][i][0], weights[j][i][1], weights[j][i][2], wires = [j])\n",
        "            if config.fullEntangle == \"Yes\":\n",
        "                for j in range(numQubits):\n",
        "                    for i in range(j):\n",
        "                        qml.CZ(wires=[j,i])\n",
        "            else:\n",
        "                for j in range(numQubits-1):\n",
        "                    qml.CZ(wires=[j,j+1])\n",
        "            \n",
        "            ##qml.Rot(*weights[0], wires=[0])\n",
        "        if config.end == \"quantum\":   \n",
        "            return qml.expval(qml.PauliZ(0))\n",
        "        else:\n",
        "            return [qml.expval(qml.PauliZ(wires=i)) for i in range(numQubits)]\n",
        "\n",
        "    weight_shapes = {\"weights\" : (config.numQubits, config.numLayers, 3)}\n",
        "    qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "\n",
        "\n",
        "    \"\"\"### Model creation\n",
        "    This cell instantiates the actual model to be run\n",
        "    \"\"\"\n",
        "\n",
        "    if config.hiddenLayer != 0:\n",
        "        clayer_1 = torch.nn.Linear(30, config.hiddenLayer)\n",
        "        \n",
        "        if config.end == \"quantum\":\n",
        "            layers = [clayer_1, qlayer]\n",
        "        else:\n",
        "            clayer_2 = torch.nn.Linear(config.numQubits, 2)\n",
        "            softmax = torch.nn.Softmax(dim=1)\n",
        "            if config.start == \"classical\":\n",
        "                layers = [clayer_1, qlayer, clayer_2, softmax]\n",
        "            else:\n",
        "                layers = [qlayer, clayer_2, softmax]\n",
        "    else:\n",
        "        layers = [qlayer]\n",
        "\n",
        "    torch.nn.init.uniform_(qlayer.weights, a=0.0, b=0.001)\n",
        "    model = torch.nn.Sequential(*layers)\n",
        "\n",
        "    \"\"\"### Training\"\"\"\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    loss = torch.nn.MSELoss()\n",
        "    x_train = torch.tensor(X_train, requires_grad=True).float()\n",
        "\n",
        "    y_train = torch.tensor(Y_train, requires_grad=False).float() if config.end == \"quantum\" else Y_hot_train.float()\n",
        "\n",
        "\n",
        "    batch_size = config.batchSize\n",
        "    batches = y_train.shape[0]/batch_size // batch_size\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        list(zip(x_train, y_train)), batch_size=5, shuffle=True, drop_last=True\n",
        "    )\n",
        "\n",
        "    epochs = config.epochs\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        running_loss = 0\n",
        "\n",
        "        for xs, ys in data_loader:\n",
        "            opt.zero_grad()\n",
        "\n",
        "            loss_evaluated = loss(model(xs), ys)\n",
        "            loss_evaluated.backward()\n",
        "\n",
        "            opt.step()\n",
        "\n",
        "            running_loss += loss_evaluated\n",
        "\n",
        "        avg_loss = running_loss / batches\n",
        "        print(\"Average loss over epoch {}: {:.4f}\".format(epoch + 1, avg_loss))\n",
        "        wandb.log({\"train_loss\":avg_loss})\n",
        "\n",
        "    \"\"\"### Training set accuracy\"\"\"\n",
        "\n",
        "    y_pred = model(x_train)\n",
        "    y_pred = y_pred.detach().numpy()  \n",
        "    if config.end == \"quantum\":\n",
        "        threshold = lambda x: 1 if x > 0 else -1 \n",
        "        vfunc = np.vectorize(threshold)\n",
        "        y_pred = vfunc(y_pred)\n",
        "        actual = Y_train\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "        actual = Y_01_train.detach().numpy()\n",
        "\n",
        "    correct = [1 if p == p_true else 0 for p, p_true in zip(y_pred, actual)]\n",
        "    accuracy = sum(correct) / len(correct)\n",
        "    print(f\"Accuracy: {accuracy * 100}%\")\n",
        "    wandb.log({\"train_acc\":accuracy})\n",
        "\n",
        "\n",
        "    \"\"\"### Testing set accuracy\"\"\"\n",
        "\n",
        "    x_test = torch.tensor(X_test, requires_grad=True).float()\n",
        "    y_pred = model(x_test)\n",
        "    y_pred = y_pred.detach().numpy()  \n",
        "    if config.end == \"quantum\":\n",
        "        threshold = lambda x: 1 if x > 0 else -1 \n",
        "        vfunc = np.vectorize(threshold)\n",
        "        y_pred = vfunc(y_pred)\n",
        "        actual = Y_test\n",
        "    else:\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "        actual = Y_01_test.detach().numpy()\n",
        "\n",
        "    correct = [1 if p == p_true else 0 for p, p_true in zip(y_pred, actual)]\n",
        "    accuracy = sum(correct) / len(correct)\n",
        "    wandb.log({\"test_acc\":accuracy})\n",
        "    print(f\"Accuracy: {accuracy * 100}%\")\n",
        "    wandb.finish()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361,
          "referenced_widgets": [
            "baaa4e57f20643b58865ac3350c38d66",
            "6079b116fcd54bc79c6d07ee83a31e95",
            "83512aa97c7f4fc0b3a00cac37f1e9b0",
            "5951537fcd36424985cd7af35e9c97ad",
            "b30291c4a01743c7b3c2256e0ee9a64c",
            "a28acdd402824d3d83776461659ac3be",
            "eb058114cb784a278d6f26830c13381c",
            "b89fd0cf70d944fe86ac68f2f0e8ad17"
          ]
        },
        "id": "aAqqDb3Yadim",
        "outputId": "1cd0d748-c2d9-4a78-c908-df4d8b0aed2a"
      },
      "source": [
        "\n",
        "\"\"\"###Global config\n",
        "For the rest of the notebook, config needs to be defined here.\n",
        "\"\"\"\n",
        "import wandb\n",
        "\n",
        "configDefault = SimpleNamespace(\n",
        "    standardScaling = \"Yes\",\n",
        "    numQubits = 2,\n",
        "    vectorNorm = \"Yes\",\n",
        "    numLayers = 1,\n",
        "    end = \"classical\",\n",
        "    fullEntangle = \"Yes\",\n",
        "    epochs = 6,\n",
        "    hiddenLayer = 5,\n",
        "    start = \"quantum\",\n",
        "    batchSize = 5\n",
        ")\n",
        "\n",
        "wandb.init(config = configDefault, project='hybrid-qnn')\n",
        "config = wandb.config\n",
        "wandbSweep(config)\n",
        "wandb.finish()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:26n8smst) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 236<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "baaa4e57f20643b58865ac3350c38d66",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210712_204344-26n8smst/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210712_204344-26n8smst/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">rare-thunder-2</strong>: <a href=\"https://wandb.ai/pj747/hybrid-qnn/runs/26n8smst\" target=\"_blank\">https://wandb.ai/pj747/hybrid-qnn/runs/26n8smst</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:26n8smst). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.33<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">confused-waterfall-3</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/pj747/hybrid-qnn\" target=\"_blank\">https://wandb.ai/pj747/hybrid-qnn</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/pj747/hybrid-qnn/runs/a2vlykey\" target=\"_blank\">https://wandb.ai/pj747/hybrid-qnn/runs/a2vlykey</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210712_204415-a2vlykey</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Average loss over epoch 1: 1.2364\n",
            "Average loss over epoch 2: 1.1822\n",
            "Average loss over epoch 3: 1.1840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz_tZU3Zay6_"
      },
      "source": [
        "wandb.agent('1fny5wr2', function=wandbSweep, entity = 'pj747', project='hybrid-qnn')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}